{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41c0f9a9-09a4-4d36-a76c-35ed1402996c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "from botocore.client import Config\n",
    "import faiss\n",
    "\n",
    "## Prompt eng\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.retrievers.bedrock import AmazonKnowledgeBasesRetriever\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain_aws import BedrockLLM\n",
    "from langchain.vectorstores import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import BedrockEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97898d89-7abd-493e-a3af-d48bcdab43e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-2\n"
     ]
    }
   ],
   "source": [
    "# Bedrock Client\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id='ACCESS_KEY',\n",
    "    aws_secret_access_key='SECRET_ACCESS_KEY',\n",
    "    aws_session_token=boto3.client('sts').assume_role(\n",
    "        RoleArn='arn:aws:iam::975050062872:role/ColabAccess',\n",
    "        RoleSessionName='ColabSession'  # You can customize the session name\n",
    "    )['Credentials']['SessionToken'],\n",
    ")\n",
    "region =session.region_name\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16cab9a8-c220-4022-b3f7-770859b9e463",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 3})\n",
    "\n",
    "bedrock_client = boto3.client(\"bedrock-runtime\", region_name = region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36fdd12b-cc4a-4dc3-b5e2-0a5972a7bbce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create/call LLM\n",
    "\n",
    "def get_llama():\n",
    "  # Create a Model\n",
    "    llm = BedrockLLM(model_id='us.meta.llama3-2-1b-instruct-v1:0',\n",
    "                client=bedrock_client,\n",
    "                model_kwargs={'max_gen_len': 300,'temperature': 0.3})\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6189fd-8361-4c82-88b9-ffa11998135c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "394958ab-4e01-427b-9ee0-82983087160d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Prompt template\n",
    "\n",
    "prompt_temp = \"\"\"\n",
    "Human: You are a expert in movies and series on netflix. You know about the actors, directors, the geners of content. \n",
    "You are good with cross reference of content. (Example: Question- What is that movie about cricket in which the \"Tare zameen par\" actor acted? \n",
    "Answer-Lagan, because As Amir khan acted in \"Tare Zameen Par\" his cricket movie is \"Lagan\".\n",
    "you should stick to the question asked about, keep answer close to facts. if the use askes to suggest contect in certain gener,\n",
    "give top 5 contect in the relevent geners. (Example: Q-Suggest me super hero movies. A-Iron Man, Avergers, Batman) Don't add subcategories and give 5 \n",
    "suggestion for each subcategoy. Just give 5 suggestion for each question. For each recomendation add 1-2 line description of content relevent to question.\n",
    "if no conetxt is given in question suggest 5 content randomly. \n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "Question: {question}\n",
    "Assistant:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_temp, input_variables=['context', 'question'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5351a16-a553-438f-849e-de7989357987",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12374/3884776118.py:2: LangChainDeprecationWarning: The class `BedrockEmbeddings` was deprecated in LangChain 0.2.11 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-aws package and should be used instead. To use it run `pip install -U :class:`~langchain-aws` and import as `from :class:`~langchain_aws import BedrockEmbeddings``.\n",
      "  bedrock_embedding = BedrockEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "# Create the embedding object again (used for loading)\n",
    "bedrock_embedding = BedrockEmbeddings(\n",
    "    model_id=\"amazon.titan-embed-text-v2:0\", \n",
    "    client=bedrock_client\n",
    ")\n",
    "\n",
    "# Load the saved FAISS index from local folder\n",
    "vectorestore_fiass = FAISS.load_local(\"faiss_index\", bedrock_embedding,allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9515a503-41f1-4eed-951e-6e59e87ebefa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get response from LLM\n",
    "\n",
    "def get_response_llm(llm, vectorestore_fiass, query):\n",
    "    retriever = vectorestore_fiass.as_retriever()\n",
    "\n",
    "    qa = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type='stuff',\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs={'prompt': prompt}\n",
    "    )\n",
    "    \n",
    "    answer = qa({'query': query})  # Now it's fine again\n",
    "    return answer['result']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0399badc-0ddd-4437-8362-6f2e0d74f5ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask your movie-related question:  comedy movies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12374/2375700674.py:14: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  answer = qa({'query': query})  # Now it's fine again\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: You are a good match for this question. Here are 5 comedy movies that you might enjoy:\n",
      "\n",
      "1. The Hangover (2009)\n",
      "2. Superbad (2007)\n",
      "3. Bridesmaids (2011)\n",
      "4. The 40-Year-Old Virgin (2005)\n",
      "5. Anchorman: The Legend of Ron Burgundy (2004)\n",
      "\n",
      "These movies are all well-known comedies that have received critical acclaim and have been popular among audiences.\n",
      "\n",
      "Would you like me to suggest more comedy movies or provide more information about these movies?\n"
     ]
    }
   ],
   "source": [
    "# Load the LLM\n",
    "llm = get_llama()\n",
    "\n",
    "# Ask a query\n",
    "query = input(\"Ask your movie-related question: \")\n",
    "\n",
    "# Get response\n",
    "response = get_response_llm(llm, vectorestore_fiass, query)  # if faiss_index is the path\n",
    "print(\"Answer:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b968b41-f0af-4a96-a022-ae075ae05d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
