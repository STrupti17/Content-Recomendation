{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k6G_Cwpccyc7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "from botocore.client import Config\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CejcJyiphNa9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# will be using Titan Embedding model called form LangChain to generate embeddings of querry\n",
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "# for Data Ingestion\n",
    "import numpy as np\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# For Vectore embedding and Vectore Store (Using Fiass DB fot embedding)\n",
    "from langchain.vectorstores import faiss\n",
    "from langchain_community.vectorstores import FAISS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wpW8uR1hfjCZ"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"hugginglearners/netflix-shows\")\n",
    "dataset = pd.DataFrame(dataset['train'])\n",
    "# dataset.to_json('/content/drive/MyDrive/Netflix_Project/data.json')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-h9dMSwHjZ_I"
   },
   "outputs": [],
   "source": [
    "# Upload the file to an S3 bucket.\n",
    "session = boto3.Session()\n",
    "s3 = session.resource('s3')\n",
    "bucket = s3.Bucket('moviedatabucket')\n",
    "# bucket.Object('dataset.json').put(Body=open('dataset.json', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E5zI_Fb6mqPq"
   },
   "outputs": [],
   "source": [
    "# Bedrock Client\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id='ACCESS_KEY',\n",
    "    aws_secret_access_key='SECREAT_ACCESS_KEY',\n",
    "    aws_session_token=boto3.client('sts').assume_role(\n",
    "        RoleArn='arn:aws:iam::975050062872:role/ColabAccess',\n",
    "        RoleSessionName='ColabSession'  # You can customize the session name\n",
    "    )['Credentials']['SessionToken'],\n",
    ")\n",
    "region =session.region_name\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cxpu7Hbbmzeg"
   },
   "outputs": [],
   "source": [
    "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 3})\n",
    "\n",
    "bedrock_client = boto3.client(\"bedrock-runtime\", region_name = region)\n",
    "\n",
    "# bedrock_client.create_evaluation_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iuiDhvcbCYkL"
   },
   "outputs": [],
   "source": [
    "# Instance for Titan Embedding model from bedrock\n",
    "bedrock_embedding = BedrockEmbeddings(model_id='amazon.titan-embed-text-v2:0',\n",
    "                                      client = bedrock_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8sn6CIxkF7v3"
   },
   "outputs": [],
   "source": [
    "# Implementing data Ingestion\n",
    "obj = bucket.Object('data.json')\n",
    "response = obj.get()\n",
    "data = json.load(response['Body'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_ingest():\n",
    "    loader = TextLoader('data.json', encoding='utf8')\n",
    "    data = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size  = 10000,\n",
    "                                                   chunk_overlap = 500)\n",
    "    doc_chunk =  text_splitter.split_documents(data)\n",
    "    return doc_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jyAb1hqAIJz3"
   },
   "outputs": [],
   "source": [
    "# Vector Embedding and Vector store\n",
    "def get_vectorestore(docs):\n",
    "    vectore_store_fiass = FAISS.from_documents(docs,\n",
    "                                               bedrock_embedding)\n",
    "    vectore_store_fiass.save_local('faiss_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o17r8FkMUZre"
   },
   "outputs": [],
   "source": [
    "doc_chunks = data_ingest()\n",
    "print(type(data_ingest()))\n",
    "get_vectorestore(doc_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rd0WI5oaGR0T"
   },
   "outputs": [],
   "source": [
    "# prompt: save a vectore on drive at given path\n",
    "file_name = \"vectore_store.pkl\"\n",
    "\n",
    "# Upload file to S3\n",
    "bucket.Object(file_name).put(Body=open(file_name, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_EkK2Ki-cCst"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
